{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**인공신경망** 은 딥러닝의 핵심이다. 인공신경망은 다재다능하고 강력하고 확장성이 좋아서 수백만 개의 이미지를 분류하거나  \n",
    "음성인식 서비스의 성능을 높이거나, 매일 수억명의 사용자에게 가장 좋은 비디오를 추천해주는 등 아주 복잡한 머신러닝 문제를 다루는데 적합하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 생물학적 뉴런에서 인공 뉴런까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 요즘엔 신경망을 훈련시키기 위한 데이터가 많다. 인공 신경망은 종종 규모가 크고 복잡한 문제에서 다른 머신러닝 기법보다 좋은 성능을 낸다.  \n",
    "  \n",
    "- 1990이후 크게 발전된 컴퓨터 하드웨어의 성능 덕분에 납득할 만한 시간안에 대규모 신경망을 훈련시킬 수 있습니다. GPU 덕분이기도 하다.  \n",
    "  \n",
    "- 훈련 알고리즘이 향상되었다.   \n",
    "  \n",
    "- 일부 인공 신경망의 이론상 제한이 실전에서는 문제가 되지 않는다고 밝혀졌다.  \n",
    "  \n",
    "- 인공 신경망이 투자와 진보의 선순환에 들어간 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.1 생물학적 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.2 뉴런을 사용한 논리 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워런 맥컬록과 월터 피츠는 매우 단순한 생물학적 뉴런 모델을 제안했는데, 나중에 이것이 **인공뉴런**이 되었다.  \n",
    "이 모델은 하나 이상의 이진 입력과 하나의 이진 출력을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.3 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 가장 간단한 인공 신경망 구조로 하나로 1957년에 프랑크 로젠블라트가 제안했다.  \n",
    "퍼셉트론은 **TLU** 라는 조금 다른 형태의 인공지능 뉴런을 기반으로 한다.  \n",
    "입력과 출력이 이진 값이 아니라 어떤 숫자고 각각의 입력 연결은 가중치와 연관되어 있습니다.  \n",
    "**TLU** 는 입력의 가중치 합을 계산하고 그런 다음 계산된 합에 **계단함수**를 적용하여 그 결과를 출력한다.  \n",
    "  \n",
    "퍼셉트론에서 가장 널리 사용되는 계단 함수는 **헤비사이드 계단 함수**입니다.  이따금 **sign function**을 대신 사용하기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 **TLU**는 간단한 선형 이진 분류 문제에 사용할 수 있습니다. 임곗값을 넘어서면 양성클래스 그렇지 않으면 음성클래스를 출력합니다.  \n",
    "**퍼셉트론** 은 층이 하나뿐인 TLU로 구성됩니다.   \n",
    "**입력뉴런** 이라 불리는 특별한 통과 뉴런을 사용해 무엇이 주입되든 그냥 출력으로 통과시킵니다.  \n",
    "보통 거기에 **편향**이 더해집니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**헤브의 규칙**: 생물학적 뉴런이 다른 뉴런을 활성화 시킬때 두 뉴런의 연결이 더 강해진다, '서로 활성화되는 세포가 서로 연결된다.'  \n",
    "퍼셉트론으로 한번에 한개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어 진다. 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 연결된 가중치를 강화 시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 출력 뉴런의 결정 경계는 선형이므로 퍼셉트론도 복잡한 패턴을 학습하지 못한다. 하지만 훈련샘플이 선형적으로 구분 될 수만 있다면 이 알고리즘이 정답에 수렴하다는 것을 보였다. 이를 **퍼셉트론 수렴 이론**이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris=load_iris()\n",
    "X=iris.data[:,(2,3)]\n",
    "y=(iris.target==0).astype(np.int)\n",
    "\n",
    "per_clf=Perceptron(random_state=42)\n",
    "per_clf.fit(X,y)\n",
    "\n",
    "y_pred=per_clf.predict([[2,0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런의 **Perceptron** 클래스는 매개변수가 loss=\"perseptron\",learning_rate=\"constant\",eta0=1(학습률),penalty=None(규제없음) 인 **SGDClassifier**와 같다.     \n",
    "    \n",
    "    \n",
    "- 로지스틱 회귀 분류기와 달리 퍼셉트론은 클래스 확률을 제공하지 않고 고정된 임곗값을 기준으로 예측을 만든다.    \n",
    "    \n",
    "    \n",
    "- 퍼셉트론의 단점은 XOR문제와 같은 간단한 문제를 풀지 못하는데 이는 다른 선형 분류기도 마찬가지다.    \n",
    "    \n",
    "    \n",
    "- 여러 퍼셉트론을 쌓아올려 일부 제약을 줄일 수 있는데 이를 **다층 퍼셉트론**이라고 한다. 이것은 XOR 문제를 풀 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.4 다층 퍼셉트론과 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트론은 입력층 하나와 은닉층이라 불리는 하나 이상의 TLU층과 마지막 층인 출력층으로 구성된다.  \n",
    "출력층을 제외한 모든 층은 편향 뉴런을 포함하며 완전히 연결되어 있다. 인공신경망의 은닉층이 2개 이상일 때 이를 **DNN**이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**역전파 훈련 알고리즘**: 후진 모드 자동 미분을 사용하는 경사하강법, 각 출력 뉴런의 오차에 마지막 은닉층의 뉴런이 얼마나 기여했는지를 측정하고 이전 은닉층에서도 같은 측정을 해 입력층까지 도달한다.   \n",
    "  \n",
    "  \n",
    "훈련 샘플에 대해 역전파 알고리즘이 먼저 예측을 만들고 (*정방향계산*) -> 오차를 측정하고 -> 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도를 측정(*역방향계산*) -> 이 오차가 감소하도록 가중치를 조금씩 조정 (*경사하겅법 스텝*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 알고리즘을 잘 작동시키기 위해 다층 퍼셉트론 구조의 계단함수를 로지스틱함수 $ \\sigma(z)=1/(1+exp(-z)) $로 바꿨다. 계단함수에는 기울기가 없지만 로지스틱함수는 어디서든지 0이 아닌 기울기가 정의되어 있다.  \n",
    "역전파 알고리즘은 로지스틱 함수 대신 다른 활성화 함수와도 사용할 수 있는데 널리 쓰이는 두 개의 다른 활성화 함수는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- 하이퍼 볼릭 탄젠트 함수 (쌍곡 탄젠트 함수)**  \n",
    "  \n",
    "$ tanh(z)=2\\sigma(2z) - 1 $ 로지스틱 함수 처럼 S자 이고 연속적이며 미분 가능합니다. 하지만 출력 범위가 -1에서 1 사이 이므로 각 층의 출력이 다소 정규화 되는 경향이 있습니다. 이는 종종 빠르게 수렴되도록 도와줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- ReLU 함수**  \n",
    "  \n",
    "  \n",
    "$ ReLU(z)=max(0,z)$. 이 함수는 연속적이지만 z=0에서 미분 가능하지 않다. 그러나 실제로는 잘 작동하고 계산 속도가 빠르다는 장점이 있다. 무엇보다 중요한 점은 출력에 최댓값이 없다는 점이 경사하강법에 있는 일부문제를 완화해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트론은 각 출력이 서로 다른 이진 클래스에 대응되는 분류문제에 자주 사용된다. 클래스가 배타적일 때는 전형적으로 출력층의 활성화 함수를 **소프트 맥스**함수로 바꿔준다.  \n",
    "  \n",
    "\n",
    "각 뉴런의 출력은 이에 상응하는 클래스의 추정 확률이 된다. 신호가 한 방향으로만 흐르기 때문에 이런 구조를 **피드포워드 신경망(FNN)** 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.2 텐서플로의 고수준 API로 다층 퍼셉트론 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로로 다층 퍼셉트론(MLP)을 훈련시키는 가장 간단한 방법은 사이킷런과 호환되는 고수준 API인 **TF.learn**을 사용하는 것이다. **DNNClassifier** 파이썬 클래스는 여러개의 은닉층과 클래스의 확률 추정을 위한 소프트 맥스 출력층으로 구성된 심층 신경망을 매우 쉽게 훈련시켜준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
